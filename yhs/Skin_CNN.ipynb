{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential,Model,load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import BatchNormalization, Lambda, Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "import cv2 as cv\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import namedtuple\n",
    "from skimage.color import rgb2lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 전처리 및 데이터 분리\n",
    "\n",
    "RESIZED_IMAGE = (200,200)\n",
    "N_CLASS = 8\n",
    "Dataset = namedtuple(\"Dataset\", [\"X\",\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tf_format(imgs) :\n",
    "    return np.stack([img[:,:, np.newaxis] for img in imgs]).astype(np.float32)\n",
    "\n",
    "def read_dataset_png(roofpath, n_labels, resize_to):\n",
    "    images, labels = [], []\n",
    "    \n",
    "    for i in range(n_labels) :\n",
    "        # 00, 01 식이니까 02d로 한다. \n",
    "        full_path = roofpath + \"/\" + format(i, \"02d\") + \"/\"\n",
    "#         print(full_path)\n",
    "        for img_name in glob.glob(full_path+\"*.png\") :\n",
    "            \n",
    "            img = plt.imread(img_name).astype(np.float32)\n",
    "            img[:,:,0] = img[:,:,0] / 255            \n",
    "    \n",
    "            label = np.zeros((n_labels), dtype=np.float)\n",
    "            label[i] = 1.0\n",
    "            \n",
    "            images.append(img.astype(np.float32))\n",
    "            labels.append(label)\n",
    "    \n",
    "    \n",
    "    return Dataset(X=to_tf_format(images), y=np.matrix(labels).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_dataset_png(\"sample_dataset2\", N_CLASS, RESIZED_IMAGE)\n",
    "print(dataset.X.shape)\n",
    "\n",
    "print(dataset.y[1, :])\n",
    "print(dataset.X[1, 1, 1, :])\n",
    "plt.imshow(dataset.X[-1, :, :, :].reshape(RESIZED_IMAGE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 200, 200, 3)\n",
      "(2000, 200, 200, 3)\n",
      "(6000, 8)\n",
      "(2000, 8)\n"
     ]
    }
   ],
   "source": [
    "# 훈련용 데이터 // 테스트 데이터 분리\n",
    "\n",
    "idx_train, idx_test = train_test_split(range(dataset.X.shape[0]), test_size=0.25, random_state=101)\n",
    "\n",
    "X_train = dataset.X[idx_train, :, :, :, :]\n",
    "X_test = dataset.X[idx_test, :, :, :, :]\n",
    "y_train = dataset.y[idx_train, :]\n",
    "y_test = dataset.y[idx_test, :]\n",
    "\n",
    "X_train = X_train.reshape(6000, 200, 200, 3)\n",
    "X_test = X_test.reshape(2000, 200, 200, 3)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 훈련 테스트 1 (실패)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련 \n",
    "def color_cnn(num_classes):\n",
    "    input_image = layer.Input(shape=(200,200,3))\n",
    "    \n",
    "    # Convolution Layer  1\n",
    "    conv_1 = layer.Convolution2D(filters=48, kernel_size=(10,10), strides=(4,4),\n",
    "                                input_shape=(200,200,3), activation='relu')(input_image)\n",
    "    conv_1 = layer.BatchNormalization()(conv_1)\n",
    "    conv_1 = layer.MaxPooling2D(pool_size=(3,3), strides=(2,2))(conv_1)\n",
    "    \n",
    "    \n",
    "#     conv_output = layer.Concatenate()([conv_1])\n",
    "    \n",
    "    flatten = layer.Flatten()(conv_1)\n",
    "    \n",
    "    # FC\n",
    "    FC_1 = layer.Dense(units=4096, activation='relu')(flatten)\n",
    "    FC_1 = layer.Dropout(0.6)(FC_1)\n",
    "    \n",
    "    output = layer.Dense(units=num_classes, activation = 'softmax')(FC_1)\n",
    "    \n",
    "    model = Model(inputs = input_image, outputs=output)\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#     model.compile(optimizer=sgd, loss='categorical_crossentropy', metrixs=['accuray'])\n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_rows, img_cols = 200, 200\n",
    "# num_classes=8\n",
    "# batch_size = 8\n",
    "# nb_epoch = 5\n",
    "\n",
    "# model = color_cnn(num_classes)\n",
    "# # model.fit_generator(training_set, steps_per_epoch=12000, epoxhs=nb_epoch, \n",
    "# #                    validation_data=test_set, validation_steps=3000, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_net(num_classes):\n",
    "    # placeholder for input image\n",
    "    input_image = Input(shape=(200,200,3))\n",
    "    # ============================================= TOP BRANCH ===================================================\n",
    "    # first top convolution layer\n",
    "    top_conv1 = Convolution2D(filters=48,kernel_size=(11,11),strides=(4,4),\n",
    "                              input_shape=(200,200,3),activation='relu')(input_image)\n",
    "    top_conv1 = BatchNormalization()(top_conv1)\n",
    "    top_conv1 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(top_conv1)\n",
    "\n",
    "    # second top convolution layer\n",
    "    # split feature map by half\n",
    "    top_top_conv2 = Lambda(lambda x : x[:,:,:,:24])(top_conv1)\n",
    "    top_bot_conv2 = Lambda(lambda x : x[:,:,:,24:])(top_conv1)\n",
    "\n",
    "    top_top_conv2 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_top_conv2)\n",
    "    top_top_conv2 = BatchNormalization()(top_top_conv2)\n",
    "    top_top_conv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(top_top_conv2)\n",
    "\n",
    "    top_bot_conv2 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_bot_conv2)\n",
    "    top_bot_conv2 = BatchNormalization()(top_bot_conv2)\n",
    "    top_bot_conv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(top_bot_conv2)\n",
    "\n",
    "    # third top convolution layer\n",
    "    # concat 2 feature map\n",
    "    top_conv3 = Concatenate()([top_top_conv2,top_bot_conv2])\n",
    "    top_conv3 = Convolution2D(filters=192,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_conv3)\n",
    "\n",
    "    # fourth top convolution layer\n",
    "    # split feature map by half\n",
    "    top_top_conv4 = Lambda(lambda x : x[:,:,:,:96])(top_conv3)\n",
    "    top_bot_conv4 = Lambda(lambda x : x[:,:,:,96:])(top_conv3)\n",
    "\n",
    "    top_top_conv4 = Convolution2D(filters=96,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_top_conv4)\n",
    "    top_bot_conv4 = Convolution2D(filters=96,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_bot_conv4)\n",
    "\n",
    "    # fifth top convolution layer\n",
    "    top_top_conv5 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_top_conv4)\n",
    "    top_top_conv5 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(top_top_conv5) \n",
    "\n",
    "    top_bot_conv5 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_bot_conv4)\n",
    "    top_bot_conv5 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(top_bot_conv5)\n",
    "\n",
    "    # ============================================= TOP BOTTOM ===================================================\n",
    "    # first bottom convolution layer\n",
    "    bottom_conv1 = Convolution2D(filters=48,kernel_size=(11,11),strides=(4,4),\n",
    "                              input_shape=(200,200,3),activation='relu')(input_image)\n",
    "    bottom_conv1 = BatchNormalization()(bottom_conv1)\n",
    "    bottom_conv1 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(bottom_conv1)\n",
    "\n",
    "    # second bottom convolution layer\n",
    "    # split feature map by half\n",
    "    bottom_top_conv2 = Lambda(lambda x : x[:,:,:,:24])(bottom_conv1)\n",
    "    bottom_bot_conv2 = Lambda(lambda x : x[:,:,:,24:])(bottom_conv1)\n",
    "\n",
    "    bottom_top_conv2 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_top_conv2)\n",
    "    bottom_top_conv2 = BatchNormalization()(bottom_top_conv2)\n",
    "    bottom_top_conv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(bottom_top_conv2)\n",
    "\n",
    "    bottom_bot_conv2 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_bot_conv2)\n",
    "    bottom_bot_conv2 = BatchNormalization()(bottom_bot_conv2)\n",
    "    bottom_bot_conv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(bottom_bot_conv2)\n",
    "\n",
    "    # third bottom convolution layer\n",
    "    # concat 2 feature map\n",
    "    bottom_conv3 = Concatenate()([bottom_top_conv2,bottom_bot_conv2])\n",
    "    bottom_conv3 = Convolution2D(filters=192,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_conv3)\n",
    "\n",
    "    # fourth bottom convolution layer\n",
    "    # split feature map by half\n",
    "    bottom_top_conv4 = Lambda(lambda x : x[:,:,:,:96])(bottom_conv3)\n",
    "    bottom_bot_conv4 = Lambda(lambda x : x[:,:,:,96:])(bottom_conv3)\n",
    "\n",
    "    bottom_top_conv4 = Convolution2D(filters=96,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_top_conv4)\n",
    "    bottom_bot_conv4 = Convolution2D(filters=96,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_bot_conv4)\n",
    "\n",
    "    # fifth bottom convolution layer\n",
    "    bottom_top_conv5 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_top_conv4)\n",
    "    bottom_top_conv5 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(bottom_top_conv5) \n",
    "\n",
    "    bottom_bot_conv5 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_bot_conv4)\n",
    "    bottom_bot_conv5 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(bottom_bot_conv5)\n",
    "\n",
    "    # ======================================== CONCATENATE TOP AND BOTTOM BRANCH =================================\n",
    "    conv_output = Concatenate()([top_top_conv5,top_bot_conv5,bottom_top_conv5,bottom_bot_conv5])\n",
    "\n",
    "    # Flatten\n",
    "    flatten = Flatten()(conv_output)\n",
    "\n",
    "    # Fully-connected layer\n",
    "    FC_1 = Dense(units=4096, activation='relu')(flatten)\n",
    "    FC_1 = Dropout(0.6)(FC_1)\n",
    "    FC_2 = Dense(units=4096, activation='relu')(FC_1)\n",
    "    FC_2 = Dropout(0.6)(FC_2)\n",
    "    output = Dense(units=num_classes, activation='softmax')(FC_2)\n",
    "    \n",
    "    model = Model(inputs=input_image,outputs=output)\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    # sgd = SGD(lr=0.01, momentum=0.9, decay=0.0005, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#     model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/20\n",
      "6000/6000 [==============================] - 83s 14ms/step - loss: 2.1088 - accuracy: 0.2398\n",
      "Epoch 2/20\n",
      "6000/6000 [==============================] - 83s 14ms/step - loss: 1.5266 - accuracy: 0.4140\n",
      "Epoch 3/20\n",
      "6000/6000 [==============================] - 81s 14ms/step - loss: 1.3523 - accuracy: 0.4862\n",
      "Epoch 4/20\n",
      "6000/6000 [==============================] - 82s 14ms/step - loss: 1.2825 - accuracy: 0.5183\n",
      "Epoch 5/20\n",
      "6000/6000 [==============================] - 81s 14ms/step - loss: 1.2189 - accuracy: 0.5493\n",
      "Epoch 6/20\n",
      "6000/6000 [==============================] - 81s 14ms/step - loss: 1.1695 - accuracy: 0.5730\n",
      "Epoch 7/20\n",
      "6000/6000 [==============================] - 82s 14ms/step - loss: 1.1226 - accuracy: 0.5832\n",
      "Epoch 8/20\n",
      "6000/6000 [==============================] - 84s 14ms/step - loss: 1.0927 - accuracy: 0.5978\n",
      "Epoch 9/20\n",
      "6000/6000 [==============================] - 82s 14ms/step - loss: 1.0636 - accuracy: 0.6075\n",
      "Epoch 10/20\n",
      "6000/6000 [==============================] - 83s 14ms/step - loss: 1.0315 - accuracy: 0.6182\n",
      "Epoch 11/20\n",
      "6000/6000 [==============================] - 83s 14ms/step - loss: 1.0011 - accuracy: 0.6340\n",
      "Epoch 12/20\n",
      "6000/6000 [==============================] - 84s 14ms/step - loss: 0.9759 - accuracy: 0.6448\n",
      "Epoch 13/20\n",
      "6000/6000 [==============================] - 84s 14ms/step - loss: 0.9661 - accuracy: 0.6472\n",
      "Epoch 14/20\n",
      "6000/6000 [==============================] - 83s 14ms/step - loss: 0.9507 - accuracy: 0.6495\n",
      "Epoch 15/20\n",
      "6000/6000 [==============================] - 84s 14ms/step - loss: 0.9272 - accuracy: 0.6607\n",
      "Epoch 16/20\n",
      "6000/6000 [==============================] - 84s 14ms/step - loss: 0.9148 - accuracy: 0.6630\n",
      "Epoch 17/20\n",
      "6000/6000 [==============================] - 84s 14ms/step - loss: 0.8925 - accuracy: 0.6710\n",
      "Epoch 18/20\n",
      "6000/6000 [==============================] - 82s 14ms/step - loss: 0.8848 - accuracy: 0.6715\n",
      "Epoch 19/20\n",
      "6000/6000 [==============================] - 83s 14ms/step - loss: 0.8723 - accuracy: 0.6825\n",
      "Epoch 20/20\n",
      "6000/6000 [==============================] - 81s 14ms/step - loss: 0.8564 - accuracy: 0.6883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x14ab1162c88>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_rows , img_cols = 200,200\n",
    "num_classes = 8\n",
    "# batch_size = 10\n",
    "# nb_epoch = 5\n",
    "\n",
    "model = color_net(num_classes)\n",
    "\n",
    "filepath = 'color_weights.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# train_datagen = ImageDataGenerator(\n",
    "#         rescale=1./255,\n",
    "#         shear_range=0.2,\n",
    "#         zoom_range=0.3,\n",
    "#         horizontal_flip=True)\n",
    "\n",
    "# training_set = train_datagen.flow_from_directory(\n",
    "#             'sample_dataset/',\n",
    "#             target_size=(img_rows, img_cols),\n",
    "#             batch_size=batch_size,\n",
    "#             class_mode='categorical')\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=256)\n",
    "\n",
    "# model.save('color_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 200, 200, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 48, 48, 48)   17472       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 48, 48, 48)   17472       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 48, 48, 48)   192         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 48, 48, 48)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 23, 23, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 23, 23, 48)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 23, 23, 24)   0           max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 23, 23, 24)   0           max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 23, 23, 24)   0           max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 23, 23, 24)   0           max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 23, 23, 64)   13888       lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 23, 23, 64)   13888       lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 23, 23, 64)   13888       lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 23, 23, 64)   13888       lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 23, 23, 64)   256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 23, 23, 64)   256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 23, 23, 64)   256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 23, 23, 64)   256         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 11, 11, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 11, 11, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 11, 11, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 11, 11, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 11, 11, 128)  0           max_pooling2d_12[0][0]           \n",
      "                                                                 max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 11, 11, 128)  0           max_pooling2d_17[0][0]           \n",
      "                                                                 max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 11, 11, 192)  221376      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 11, 11, 192)  221376      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 11, 11, 96)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 11, 11, 96)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 11, 11, 96)   0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 11, 11, 96)   0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 11, 11, 96)   83040       lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 11, 11, 96)   83040       lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 11, 11, 96)   83040       lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 11, 11, 96)   83040       lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 11, 11, 64)   55360       conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 11, 11, 64)   55360       conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 11, 11, 64)   55360       conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 11, 11, 64)   55360       conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 5, 5, 64)     0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 5, 5, 64)     0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 5, 5, 64)     0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 5, 5, 64)     0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 5, 5, 256)    0           max_pooling2d_14[0][0]           \n",
      "                                                                 max_pooling2d_15[0][0]           \n",
      "                                                                 max_pooling2d_19[0][0]           \n",
      "                                                                 max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 6400)         0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 4096)         26218496    flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 4096)         0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 4096)         16781312    dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 4096)         0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 8)            32776       dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 44,120,840\n",
      "Trainable params: 44,120,136\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 :  0.5874999761581421\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(\"정확도 : \", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 120, 3)\n",
      "(1, 200, 200, 3)\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img = plt.imread('sample_dataset/05/1.png').reshape(1,200,200,3)\n",
    "img = cv.imread('test_img/1.jpg')\n",
    "print(img.shape)\n",
    "img = cv.resize(img, dsize=(200, 200), interpolation=cv.INTER_AREA)\n",
    "\n",
    "img = np.stack([i[:,:, np.newaxis] for i in img]).astype(np.float32)\n",
    "img = img.reshape(1,200,200,3)\n",
    "print(img.shape)\n",
    "\n",
    "\n",
    "prediction = model.predict(img)\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 120, 3)\n",
      "(1, 200, 200, 3)\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원빈 결과 (실제값 WAD  2) (결과 WAM)\n",
    "# img = plt.imread('sample_dataset/05/1.png').reshape(1,200,200,3)\n",
    "img = cv.imread('test_img/1.jpg')\n",
    "print(img.shape)\n",
    "img = cv.resize(img, dsize=(200, 200), interpolation=cv.INTER_AREA)\n",
    "\n",
    "img = np.stack([i[:,:, np.newaxis] for i in img]).astype(np.float32)\n",
    "img = img.reshape(1,200,200,3)\n",
    "print(img.shape)\n",
    "\n",
    "\n",
    "prediction = model.predict(img)\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(164, 164, 3)\n",
      "(1, 200, 200, 3)\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이영애  (실제값 CSL  4) (결과 WSL)\n",
    "# img = plt.imread('sample_dataset/05/1.png').reshape(1,200,200,3)\n",
    "img = cv.imread('test_img/2.jpg')\n",
    "print(img.shape)\n",
    "img = cv.resize(img, dsize=(200, 200), interpolation=cv.INTER_AREA)\n",
    "\n",
    "img = np.stack([i[:,:, np.newaxis] for i in img]).astype(np.float32)\n",
    "img = img.reshape(1,200,200,3)\n",
    "print(img.shape)\n",
    "\n",
    "\n",
    "prediction = model.predict(img)\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 120, 3)\n",
      "(1, 200, 200, 3)\n",
      "[[0.000000e+00 0.000000e+00 0.000000e+00 6.393256e-15 0.000000e+00\n",
      "  0.000000e+00 0.000000e+00 1.000000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이효리 (WAB  )  (결과 CWD)\n",
    "# img = plt.imread('sample_dataset/05/1.png').reshape(1,200,200,3)\n",
    "img = cv.imread('test_img/3.jpg')\n",
    "print(img.shape)\n",
    "img = cv.resize(img, dsize=(200, 200), interpolation=cv.INTER_AREA)\n",
    "\n",
    "img = np.stack([i[:,:, np.newaxis] for i in img]).astype(np.float32)\n",
    "img = img.reshape(1,200,200,3)\n",
    "print(img.shape)\n",
    "\n",
    "\n",
    "prediction = model.predict(img)\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
