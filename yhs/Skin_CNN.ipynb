{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential,Model,load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import BatchNormalization, Lambda, Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "import cv2 as cv\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import namedtuple\n",
    "from skimage.color import rgb2lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 전처리 및 데이터 분리\n",
    "\n",
    "RESIZED_IMAGE = (200,200)\n",
    "N_CLASS = 8\n",
    "Dataset = namedtuple(\"Dataset\", [\"X\",\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tf_format(imgs) :\n",
    "    return np.stack([img[:,:, np.newaxis] for img in imgs]).astype(np.float32)\n",
    "\n",
    "def read_dataset_png(roofpath, n_labels, resize_to):\n",
    "    images, labels = [], []\n",
    "    \n",
    "    for i in range(n_labels) :\n",
    "        # 00, 01 식이니까 02d로 한다. \n",
    "        full_path = roofpath + \"/\" + format(i, \"02d\") + \"/\"\n",
    "#         print(full_path)\n",
    "        for img_name in glob.glob(full_path+\"*.png\") :\n",
    "            \n",
    "            img = plt.imread(img_name).astype(np.float32)\n",
    "            img[:,:,0] = img[:,:,0] / 255            \n",
    "    \n",
    "            label = np.zeros((n_labels), dtype=np.float)\n",
    "            label[i] = 1.0\n",
    "            \n",
    "            images.append(img.astype(np.float32))\n",
    "            labels.append(label)\n",
    "    \n",
    "    \n",
    "    return Dataset(X=to_tf_format(images), y=np.matrix(labels).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 200, 200, 1, 3)\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0.00012303 0.02745098 0.01960784]]\n"
     ]
    }
   ],
   "source": [
    "dataset = read_dataset_png(\"sample_dataset\", N_CLASS, RESIZED_IMAGE)\n",
    "print(dataset.X.shape)\n",
    "\n",
    "print(dataset.y[1, :])\n",
    "print(dataset.X[1, 1, 1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 200, 200, 3)\n",
      "(200, 200, 200, 3)\n",
      "(600, 8)\n",
      "(200, 8)\n"
     ]
    }
   ],
   "source": [
    "# 훈련용 데이터 // 테스트 데이터 분리\n",
    "\n",
    "idx_train, idx_test = train_test_split(range(dataset.X.shape[0]), test_size=0.25, random_state=101)\n",
    "\n",
    "X_train = dataset.X[idx_train, :, :, :, :]\n",
    "X_test = dataset.X[idx_test, :, :, :, :]\n",
    "y_train = dataset.y[idx_train, :]\n",
    "y_test = dataset.y[idx_test, :]\n",
    "\n",
    "# X_train = X_train.reshape(600, 200, 200, 3)\n",
    "# X_test = X_test.reshape(200, 200, 200, 3)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 훈련 테스트 1 (실패)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련 \n",
    "def color_cnn(num_classes):\n",
    "    input_image = layer.Input(shape=(200,200,3))\n",
    "    \n",
    "    # Convolution Layer  1\n",
    "    conv_1 = layer.Convolution2D(filters=48, kernel_size=(10,10), strides=(4,4),\n",
    "                                input_shape=(200,200,3), activation='relu')(input_image)\n",
    "    conv_1 = layer.BatchNormalization()(conv_1)\n",
    "    conv_1 = layer.MaxPooling2D(pool_size=(3,3), strides=(2,2))(conv_1)\n",
    "    \n",
    "    \n",
    "#     conv_output = layer.Concatenate()([conv_1])\n",
    "    \n",
    "    flatten = layer.Flatten()(conv_1)\n",
    "    \n",
    "    # FC\n",
    "    FC_1 = layer.Dense(units=4096, activation='relu')(flatten)\n",
    "    FC_1 = layer.Dropout(0.6)(FC_1)\n",
    "    \n",
    "    output = layer.Dense(units=num_classes, activation = 'softmax')(FC_1)\n",
    "    \n",
    "    model = Model(inputs = input_image, outputs=output)\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#     model.compile(optimizer=sgd, loss='categorical_crossentropy', metrixs=['accuray'])\n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 200, 200\n",
    "num_classes=8\n",
    "batch_size = 8\n",
    "nb_epoch = 5\n",
    "\n",
    "model = color_cnn(num_classes)\n",
    "# model.fit_generator(training_set, steps_per_epoch=12000, epoxhs=nb_epoch, \n",
    "#                    validation_data=test_set, validation_steps=3000, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_net(num_classes):\n",
    "    # placeholder for input image\n",
    "    input_image = Input(shape=(200,200,3))\n",
    "    # ============================================= TOP BRANCH ===================================================\n",
    "    # first top convolution layer\n",
    "    top_conv1 = Convolution2D(filters=48,kernel_size=(11,11),strides=(4,4),\n",
    "                              input_shape=(224,224,3),activation='relu')(input_image)\n",
    "    top_conv1 = BatchNormalization()(top_conv1)\n",
    "    top_conv1 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(top_conv1)\n",
    "\n",
    "    # second top convolution layer\n",
    "    # split feature map by half\n",
    "    top_top_conv2 = Lambda(lambda x : x[:,:,:,:24])(top_conv1)\n",
    "    top_bot_conv2 = Lambda(lambda x : x[:,:,:,24:])(top_conv1)\n",
    "\n",
    "    top_top_conv2 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_top_conv2)\n",
    "    top_top_conv2 = BatchNormalization()(top_top_conv2)\n",
    "    top_top_conv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(top_top_conv2)\n",
    "\n",
    "    top_bot_conv2 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_bot_conv2)\n",
    "    top_bot_conv2 = BatchNormalization()(top_bot_conv2)\n",
    "    top_bot_conv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(top_bot_conv2)\n",
    "\n",
    "    # third top convolution layer\n",
    "    # concat 2 feature map\n",
    "    top_conv3 = Concatenate()([top_top_conv2,top_bot_conv2])\n",
    "    top_conv3 = Convolution2D(filters=192,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_conv3)\n",
    "\n",
    "    # fourth top convolution layer\n",
    "    # split feature map by half\n",
    "    top_top_conv4 = Lambda(lambda x : x[:,:,:,:96])(top_conv3)\n",
    "    top_bot_conv4 = Lambda(lambda x : x[:,:,:,96:])(top_conv3)\n",
    "\n",
    "    top_top_conv4 = Convolution2D(filters=96,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_top_conv4)\n",
    "    top_bot_conv4 = Convolution2D(filters=96,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_bot_conv4)\n",
    "\n",
    "    # fifth top convolution layer\n",
    "    top_top_conv5 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_top_conv4)\n",
    "    top_top_conv5 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(top_top_conv5) \n",
    "\n",
    "    top_bot_conv5 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_bot_conv4)\n",
    "    top_bot_conv5 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(top_bot_conv5)\n",
    "\n",
    "    # ============================================= TOP BOTTOM ===================================================\n",
    "    # first bottom convolution layer\n",
    "    bottom_conv1 = Convolution2D(filters=48,kernel_size=(11,11),strides=(4,4),\n",
    "                              input_shape=(227,227,3),activation='relu')(input_image)\n",
    "    bottom_conv1 = BatchNormalization()(bottom_conv1)\n",
    "    bottom_conv1 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(bottom_conv1)\n",
    "\n",
    "    # second bottom convolution layer\n",
    "    # split feature map by half\n",
    "    bottom_top_conv2 = Lambda(lambda x : x[:,:,:,:24])(bottom_conv1)\n",
    "    bottom_bot_conv2 = Lambda(lambda x : x[:,:,:,24:])(bottom_conv1)\n",
    "\n",
    "    bottom_top_conv2 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_top_conv2)\n",
    "    bottom_top_conv2 = BatchNormalization()(bottom_top_conv2)\n",
    "    bottom_top_conv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(bottom_top_conv2)\n",
    "\n",
    "    bottom_bot_conv2 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_bot_conv2)\n",
    "    bottom_bot_conv2 = BatchNormalization()(bottom_bot_conv2)\n",
    "    bottom_bot_conv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(bottom_bot_conv2)\n",
    "\n",
    "    # third bottom convolution layer\n",
    "    # concat 2 feature map\n",
    "    bottom_conv3 = Concatenate()([bottom_top_conv2,bottom_bot_conv2])\n",
    "    bottom_conv3 = Convolution2D(filters=192,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_conv3)\n",
    "\n",
    "    # fourth bottom convolution layer\n",
    "    # split feature map by half\n",
    "    bottom_top_conv4 = Lambda(lambda x : x[:,:,:,:96])(bottom_conv3)\n",
    "    bottom_bot_conv4 = Lambda(lambda x : x[:,:,:,96:])(bottom_conv3)\n",
    "\n",
    "    bottom_top_conv4 = Convolution2D(filters=96,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_top_conv4)\n",
    "    bottom_bot_conv4 = Convolution2D(filters=96,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_bot_conv4)\n",
    "\n",
    "    # fifth bottom convolution layer\n",
    "    bottom_top_conv5 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_top_conv4)\n",
    "    bottom_top_conv5 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(bottom_top_conv5) \n",
    "\n",
    "    bottom_bot_conv5 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_bot_conv4)\n",
    "    bottom_bot_conv5 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(bottom_bot_conv5)\n",
    "\n",
    "    # ======================================== CONCATENATE TOP AND BOTTOM BRANCH =================================\n",
    "    conv_output = Concatenate()([top_top_conv5,top_bot_conv5,bottom_top_conv5,bottom_bot_conv5])\n",
    "\n",
    "    # Flatten\n",
    "    flatten = Flatten()(conv_output)\n",
    "\n",
    "    # Fully-connected layer\n",
    "    FC_1 = Dense(units=4096, activation='relu')(flatten)\n",
    "    FC_1 = Dropout(0.6)(FC_1)\n",
    "    FC_2 = Dense(units=4096, activation='relu')(FC_1)\n",
    "    FC_2 = Dropout(0.6)(FC_2)\n",
    "    output = Dense(units=num_classes, activation='softmax')(FC_2)\n",
    "    \n",
    "    model = Model(inputs=input_image,outputs=output)\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    # sgd = SGD(lr=0.01, momentum=0.9, decay=0.0005, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#     model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 2.7654 - accuracy: 0.1267\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 7s 12ms/step - loss: 2.5018 - accuracy: 0.1550\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 2.1317 - accuracy: 0.2133\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 2.0218 - accuracy: 0.2283\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 1.9337 - accuracy: 0.2567\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 1.8806 - accuracy: 0.3067\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 1.6675 - accuracy: 0.4150\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 1.5864 - accuracy: 0.4333\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 1.4946 - accuracy: 0.4850\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 1.4091 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x16d549e1888>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_rows , img_cols = 200,200\n",
    "num_classes = 8\n",
    "batch_size = 10\n",
    "nb_epoch = 5\n",
    "\n",
    "model = color_net(num_classes)\n",
    "\n",
    "filepath = 'color_weights.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# train_datagen = ImageDataGenerator(\n",
    "#         rescale=1./255,\n",
    "#         shear_range=0.2,\n",
    "#         zoom_range=0.3,\n",
    "#         horizontal_flip=True)\n",
    "\n",
    "# training_set = train_datagen.flow_from_directory(\n",
    "#             'sample_dataset/',\n",
    "#             target_size=(img_rows, img_cols),\n",
    "#             batch_size=batch_size,\n",
    "#             class_mode='categorical')\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=200)\n",
    "\n",
    "# model.save('color_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 200, 200, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 48, 48, 48)   17472       input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 48, 48, 48)   17472       input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 48, 48, 48)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 48, 48, 48)   192         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 23, 23, 48)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 23, 23, 48)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 23, 23, 24)   0           max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 23, 23, 24)   0           max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 23, 23, 24)   0           max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 23, 23, 24)   0           max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 23, 23, 64)   13888       lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 23, 23, 64)   13888       lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 23, 23, 64)   13888       lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 23, 23, 64)   13888       lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 23, 23, 64)   256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 23, 23, 64)   256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 23, 23, 64)   256         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 23, 23, 64)   256         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 11, 11, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 11, 11, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 11, 11, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 11, 11, 64)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 11, 11, 128)  0           max_pooling2d_17[0][0]           \n",
      "                                                                 max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 11, 11, 128)  0           max_pooling2d_22[0][0]           \n",
      "                                                                 max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 11, 11, 192)  221376      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 11, 11, 192)  221376      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 11, 11, 96)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 11, 11, 96)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 11, 11, 96)   0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 11, 11, 96)   0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 11, 11, 96)   83040       lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 11, 11, 96)   83040       lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 11, 11, 96)   83040       lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 11, 11, 96)   83040       lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 11, 11, 64)   55360       conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 11, 11, 64)   55360       conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 11, 11, 64)   55360       conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 11, 11, 64)   55360       conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 5, 5, 64)     0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 5, 5, 64)     0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D) (None, 5, 5, 64)     0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling2D) (None, 5, 5, 64)     0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 5, 5, 256)    0           max_pooling2d_19[0][0]           \n",
      "                                                                 max_pooling2d_20[0][0]           \n",
      "                                                                 max_pooling2d_24[0][0]           \n",
      "                                                                 max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 6400)         0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 4096)         26218496    flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 4096)         0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 4096)         16781312    dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 4096)         0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 8)            32776       dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 44,120,840\n",
      "Trainable params: 44,120,136\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 :  0.15000000596046448\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(\"정확도 : \", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13276604 0.13394688 0.12253062 0.1241414  0.13202977 0.12832576\n",
      "  0.11807491 0.10818469]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = plt.imread('sample_dataset/05/1.png').reshape(1,200,200,3)\n",
    "\n",
    "prediction = model.predict(img)\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "np.argmax(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
