{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 옷 분리\n",
    "    \n",
    "    최초 작성일 : 20/03/09\n",
    "    작성자 : 양희승\n",
    "    \n",
    "    작성내용 : 무신사 이미지를 통해 옷 색깔 판별하기 위한 옷분리 코드\n",
    "    \n",
    "    \n",
    "    수정내용 :\n",
    "        전체 코드 수정\n",
    "        \n",
    "        20/03/20\n",
    "            - 분리코드 수정\n",
    "            - DB 적재 코드 추가\n",
    "            - 옷 색 판별 코드 추가\n",
    "            \n",
    "        20/03/23\n",
    "            - 분리코드 수정  이미지 RGBA -> 투명배경 흰색 처리\n",
    "            - DB연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\users\\yhs\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py:1752: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## DB 연결 데이터 \n",
    "# config = {\"host\":\"192.168.0.12\", \"user\":\"cai\", \"passwd\":\"1234\", \"db\":\"final\"}\n",
    "config = {\"host\":\"49.142.181.65\", \"user\":\"cai\",\"passwd\":\"1234\", \"db\":\"final\"}\n",
    "conn = pymysql.connect(**config)\n",
    "\n",
    "# 모델, file name저장\n",
    "files = os.listdir(\"Fashion-AI/input/\")\n",
    "model = load_model(\"Fashion-AI/model/topwears.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  옷 분할\n",
    "\n",
    "class fashion_tools(object):\n",
    "    def __init__(self,imageid,version=1.1):\n",
    "        self.imageid = imageid\n",
    "        self.model = model\n",
    "        self.version = version\n",
    "        \n",
    "    def get_dress(self,stack=False):\n",
    "        name =  self.imageid\n",
    "        file = cv.imread(name)\n",
    "        file = tf.image.resize_with_pad(file,target_height=512,target_width=512)\n",
    "        rgb  = file.numpy()\n",
    "        file = np.expand_dims(file,axis=0)/ 255.\n",
    "        seq = self.model.predict(file)\n",
    "        seq = seq[3][0,:,:,0]\n",
    "        seq = np.expand_dims(seq,axis=-1)\n",
    "        c1x = rgb*seq\n",
    "        c2x = rgb*(1-seq)\n",
    "        cfx = c1x+c2x\n",
    "        dummy = np.ones((rgb.shape[0],rgb.shape[1],1))\n",
    "        rgbx = np.concatenate((rgb,dummy*255),axis=-1)\n",
    "        rgbs = np.concatenate((cfx,seq*255.),axis=-1)\n",
    "        if stack:\n",
    "            stacked = np.hstack((rgbx,rgbs))\n",
    "            return stacked\n",
    "        else:\n",
    "            alpha_val = np.zeros((512,512))\n",
    "            result = np.array(rgbs[:,:,0:3])\n",
    "            for i in range(len(rgbs[:,:,3])) :\n",
    "                for j in range(len(rgbs[:,:,3][i])):\n",
    "                    alpha_val[i][j] = round(rgbs[:,:,3][i][j], 2)\n",
    "            \n",
    "            for i in range(len(alpha_val)) :\n",
    "                for j in range(len(alpha_val[i])) :\n",
    "                    if (alpha_val[i][j] <= 0.95) :\n",
    "                        result[i][j][0] = 255.0\n",
    "                        result[i][j][1] = 255.0\n",
    "                        result[i][j][2] = 255.0                        \n",
    "            return result\n",
    "        \n",
    "#     def get_patch(self):\n",
    "#         return None\n",
    "    \n",
    "#     def development(self):\n",
    "#         n_ = '\\n'\n",
    "#         return (f\"VERSION : {self.version} {n_} Interesting tools to be added to the workflow pipe!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "숫자만 입력 : 1\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "idx = int(input(\"숫자만 입력 : \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\thresh.cpp:1529: error: (-215:Assertion failed) src.type() == CV_8UC1 in function 'cv::threshold'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-155-631605842a84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_BINARY_INV\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_OTSU\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\thresh.cpp:1529: error: (-215:Assertion failed) src.type() == CV_8UC1 in function 'cv::threshold'\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for i in range(idx) :\n",
    "    \n",
    "#     f = \"Fashion-AI/input/\"+files[i]\n",
    "    f = \"Fashion-AI/input/27651.jpg\"\n",
    "    o = \"Fashion-AI/output/\"+files[i].replace(\".jpg\", \"\")\n",
    "    api    = fashion_tools(f, model)    \n",
    "    image_ = api.get_dress(False)    \n",
    "    \n",
    "end_time = time.time()\n",
    "print(\"total time : \", end_time - start_time, \"초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = \"Fashion-AI/input/27651.jpg\"\n",
    "o = \"Fashion-AI/output/\"+files[i].replace(\".jpg\", \"\")\n",
    "api    = fashion_tools(f, model)    \n",
    "image_ = api.get_dress(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배경색처리 - 8번 오류\n",
    "# cv2.namedWindow(‘image’, cv2.WINDOW_NORMAL)\n",
    "\n",
    "def kim(img) :\n",
    "#     img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    imgo = img\n",
    "    height, width = imgo.shape[:2]\n",
    "\n",
    "    #Create a mask holder\n",
    "    mask = np.zeros(imgo.shape[:2],np.uint8)\n",
    "\n",
    "    #Grab Cut the object\n",
    "    bgdModel = np.zeros((1,65),np.float64)\n",
    "    fgdModel = np.zeros((1,65),np.float64)\n",
    "\n",
    "    #Hard Coding the Rect… The object must lie within this rect.\n",
    "    rect = (10,10,width-30,height-30)\n",
    "    cv.grabCut(imgo,mask,rect,bgdModel,fgdModel,5,cv.GC_INIT_WITH_RECT)\n",
    "    mask = np.where((mask==2)|(mask==0),0,1).astype(\"uint8\")\n",
    "    img1 = imgo*mask[:,:,np.newaxis]\n",
    "\n",
    "    #Get the background\n",
    "    background = imgo-img1\n",
    "\n",
    "    #Change all pixels in the background that are not black to white\n",
    "    background[np.where((background > [0,0,0]).all(axis = 2))] = [255,255,255]\n",
    "\n",
    "    #Add the background and the image\n",
    "    final = background + img1\n",
    "\n",
    "    #To be done – Smoothening the edges….\n",
    "\n",
    "    # plt.imshow(\"image\", final )\n",
    "#     cv.imwrite(\"img/clothes_test/ext_\"+file_name+\".jpg\", final)\n",
    "#     plt.imshow(final)\n",
    "#     plt.show()\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## 경계값 처리\n",
    "\n",
    "def test(img) :\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv.threshold(gray, 0, 255, cv.THRESH_BINARY_INV+cv.THRESH_OTSU)\n",
    "\n",
    "\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    opening = cv.morphologyEx(thresh, cv.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "    sure_bg = cv.dilate(opening, kernel, iterations=3)\n",
    "\n",
    "    dist_transform = cv.distanceTransform(opening, cv.DIST_L2, 5)\n",
    "\n",
    "    ret, sure_fg = cv.threshold(dist_transform, 0.5*dist_transform.max(), 255,0)\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "\n",
    "    unknown = cv.subtract(sure_bg, sure_fg)\n",
    "\n",
    "    ret, markers = cv.connectedComponents(sure_fg)\n",
    "    markers = markers+1\n",
    "\n",
    "    markers[unknown == 255] = 0\n",
    "\n",
    "\n",
    "    markers = cv.watershed(img, markers)\n",
    "    img[markers == -1] = [ 255, 0 , 0]\n",
    "\n",
    "    images = [gray, thresh, sure_g, dist_transform, sure_fg, unknown, markers, img]\n",
    "\n",
    "    titles = ['Gray', 'Binary', 'Sure BG', 'Distance', 'Sure FG', 'Unknown', 'Markers', 'Result']\n",
    "\n",
    "    for i in range(len(images)) :\n",
    "        plt.subplot(2,4,i+1), plt.imshow(images[i]), plt.title(titles[i]), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\grabcut.cpp:557: error: (-5:Bad argument) image must have CV_8UC3 type in function 'cv::grabCut'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-178-d5fe450c3369>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m161\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m79\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrabCut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrect\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbgdModel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfgdModel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGC_INIT_WITH_RECT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mmask2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m|\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'uint8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmask2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\grabcut.cpp:557: error: (-5:Bad argument) image must have CV_8UC3 type in function 'cv::grabCut'\n"
     ]
    }
   ],
   "source": [
    "img = image_/255\n",
    "\n",
    "mask = np.zeros(img.shape[:2],np.uint8)\n",
    "\n",
    "bgdModel = np.zeros((1,65),np.float64)\n",
    "fgdModel = np.zeros((1,65),np.float64)\n",
    "\n",
    "rect = (161,79,150,150)\n",
    "\n",
    "cv.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv.GC_INIT_WITH_RECT)\n",
    "mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "img = img*mask2[:,:,np.newaxis]\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\grabcut.cpp:557: error: (-5:Bad argument) image must have CV_8UC3 type in function 'cv::grabCut'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-135-11098b6794a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-134-f79ea12b5c3f>\u001b[0m in \u001b[0;36mkim\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m#Hard Coding the Rect… The object must lie within this rect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrabCut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrect\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbgdModel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfgdModel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGC_INIT_WITH_RECT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m|\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"uint8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mimg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimgo\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\grabcut.cpp:557: error: (-5:Bad argument) image must have CV_8UC3 type in function 'cv::grabCut'\n"
     ]
    }
   ],
   "source": [
    "result = kim(image_)\n",
    "plt.imshow(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
